---
title: "Prediction of Tornado Occurance in the Twin Cities"
subtitle: "INFO 523 - Summer 2025 - Final Project"
author: "The Crengineers - Tyler Hart"
title-slide-attributes:
  data-background-image: images/1024px-Tornado_Alley_Diagram.png
  data-background-size: stretch
  data-background-opacity: "0.3"
  data-slide-number: none
format:
  revealjs:
    theme:  ['data/customtheming.scss']
  
editor: visual
jupyter: python3
execute:
  echo: false
  freeze: auto  # re-render only when source changes
---

```{python}
#| label: load-packages
#| echo: false

# Load packages here
import numpy as np
import statsmodels.api as sm
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import PySimpleGUI as sg
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import NearestNeighbors
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV,cross_val_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report,roc_curve, roc_auc_score, accuracy_score
from sklearn.decomposition import PCA
import ipywidgets as widgets
from IPython.display import display, clear_output

```

```{python}
#| label: setup
#| echo: false
#| 
# Set up plot theme and figure resolution
sns.set_theme(style="whitegrid")
sns.set_context("notebook", font_scale=1.1)

plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['figure.figsize'] = (6, 6 * 0.618)
```

```{python}
#| label: load-data
#| include: false
# Load data in Python
AllDaysWithTornados = pd.read_csv('data/tornado_days.csv')
```

# Introduction

## Why Tornadoes in the Twin Cities

-   Unfortunately I have had friends and family affected by devastationg tornados

-   My family lives in the Twin Cities which while towards the top of tornado alley is still in its "alley" of influence

- Daily weather is a part of everyones lives. Living in Tucson now, I check it at least 10 times a day in the summer. 

## DataSets

More Detailed dataset information can be found at [Data Dictionary](https://github.com/INFO-523-SU25/final-project-hart/blob/main/data/README.md)

::: {.panel-tabset}

## Data Description

- Two Datasets:

  - Minnesota NOAA Tornado Archive:

    - Contains data on every reported tornado event as far back as 1952.

    - Includes tornado statistics such as location, size, damage

  - Minneapolis Saint-Paul (MSP/Twin Cities) daily weather data:

    - Gathered daily weather data from MSP International Airport.

    - Includes all daily data as far back as 2000 including wind direction, temperature, surface pressure, etc.

    - Gathered from open meteo API. Saved in repo for convience. 

## Area of Interest

![MN Counties of Interest](images/MN_counties.png){fig-align="center" width="500"}

- Because the daily weather data is gathered from MSP International Airport

- I chose a 50 mile radius around the airport.

- Eliminated Wisconson counties to accomodate data sets.

- Lastly my family lives there and thus I have an attachment to the area. :)

## Data Head

Merged Variables I care about with Feature Engineering Features

```{python}
#| label: data-head
#| include: false
# Show Head in Python

AllDaysWithTornados = AllDaysWithTornados.drop('Unnamed: 0', axis=1)
AllDaysWithTornados['CZ_NAME_STR'] = AllDaysWithTornados['CZ_NAME_STR'].fillna('None')
AllDaysWithTornados['TOR_F_SCALE'] = AllDaysWithTornados['TOR_F_SCALE'].fillna('None')
AllDaysWithTornados.head().to_html()

```
:::


## Exploratory Data Analysis

::: {.panel-tabset}

## Tornado Occurred Relations
```{python}

sns.pairplot(data=AllDaysWithTornados, x_vars=['temperature_2m_mean', 'precipitation_sum', 'dew_point_2m_mean', 'wind_direction_10m_dominant', 'surface_pressure_mean', 'wind_gusts_10m_max', 'wind_speed_10m_max', 'date', 'relative_humidity_2m_mean', 'time_of_year', 'weather_code'], y_vars=['tornado_occurred'])
plt.show()
```

- Clear conditions for some variables that contribute to a tornado.

  - Time of year due to seasonality of tornados in Tornado Alley

  - Daily Values like temperature mean and dew point mean

## Date Relations

```{python}
sns.pairplot(data=AllDaysWithTornados, x_vars=['temperature_2m_mean', 'precipitation_sum', 'dew_point_2m_mean', 'wind_direction_10m_dominant', 'surface_pressure_mean', 'wind_gusts_10m_max', 'wind_speed_10m_max', 'relative_humidity_2m_mean', 'tornado_occurred', 'time_of_year', 'weather_code'], y_vars=['date'])
plt.show()
```

- Most Variables are randomly distributed. 

- Univariate Analysis (not pictured here for time) shows fairly normal distributions for major weather parameters. 

- Precipitation sum might be a parameter to keep in mind for skew

## Time of Year Relations

```{python}
sns.pairplot(data=AllDaysWithTornados, x_vars=['temperature_2m_mean', 'precipitation_sum', 'dew_point_2m_mean', 'wind_direction_10m_dominant', 'surface_pressure_mean', 'wind_gusts_10m_max', 'wind_speed_10m_max', 'relative_humidity_2m_mean', 'tornado_occurred', 'date', 'weather_code'], y_vars=['time_of_year'])
plt.show()

```

- Weather conditions are a function of time of year. This makes sense as certain conditions are seasonal. 

- Non-seasonal parameters appear normally distibuted. 

:::

## Model Creation and Results:

4 Models were created to see which one was best. 
```{python}
ScaledTornados = AllDaysWithTornados.copy()
ScaledTornados.head()
dropped = ScaledTornados.drop('tornado_occurred', axis = 1)
numerical_cols = dropped.select_dtypes(include = ['int64', 'float64']).columns
scaler = StandardScaler()
ScaledTornados[numerical_cols] = scaler.fit_transform(ScaledTornados[numerical_cols])

feature_names = ScaledTornados.drop(['tornado_occurred', 'CZ_NAME_STR', 'TOR_F_SCALE', 'TOR_LENGTH', 'TOR_WIDTH', 'date'], axis = 1).columns.to_list()
X = ScaledTornados[feature_names]
y = ScaledTornados['tornado_occurred']

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=63)

X_train_with_const = sm.add_constant(X_train)
X_test_with_const = sm.add_constant(X_test)
X_train_with_const = X_train_with_const.astype(int)
X_test_with_const = X_test_with_const.astype(int)
```
::: {.panel-tabset}

## Logistic Regression
```{python}
#| label: logreg-model
#| message: false
# Model Creation
# All param grids generated by copilot when asked for a param grid for {model_type}

logreg_params = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l2', 'l1'],
    'solver': ['liblinear', 'saga'],
    'class_weight': [None, 'balanced'],
    'max_iter': [100, 500, 1000]
}

logreg_model = LogisticRegression(random_state=63)
logreg_grid = RandomizedSearchCV(logreg_model, param_distributions = logreg_params, cv = 5, scoring = 'recall_macro', n_iter = 100, random_state = 63)
logreg_grid.fit(X_train, y_train)
```

* **Logistic Regression**
  * Rationale: 
  * Chosen Hyper-Parameters:
  ```{python}
  print("Best LR parameters:", logreg_grid.best_params_)
  ```
  * Results: 
  ```{python}
  print("Best LR score:", logreg_grid.best_score_)
  ```

## Naive Bayes

```{python}
#| label: bayes-model
#| message: false
# Model Creation
# All param grids generated by copilot when asked for a param grid for {model_type}
bayes_params = {
    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]
}

bayes_model = GaussianNB()
bayes_grid = RandomizedSearchCV(bayes_model, param_distributions = bayes_params, cv = 5, scoring = 'recall_macro', n_iter = 100, random_state = 63)
bayes_grid.fit(X_train, y_train)
```

bayes_grid.fit(X_train, y_train)
* **Naive Bayes**
  * Rationale: 
  * Chosen Hyper-Parameters:
    ```{python}
    print("Best Bayes parameters:", bayes_grid.best_params_)
    ```
  * Results: 
   ```{python}
   print("Best Bayes score:", bayes_grid.best_score_)
   ```

## Support Vector Machines

```{python}
#| label: svc-model
#| message: false
# Model Creation
# All param grids generated by copilot when asked for a param grid for {model_type}
svc_params = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto', 0.01, 0.1, 1],
    'degree': [2, 3, 4]  # Only used for 'poly' kernel
}
svc_model = svm.SVC(random_state = 63)
svc_grid = RandomizedSearchCV(svc_model, param_distributions = svc_params, cv = 5, scoring = 'recall_macro', n_iter = 100, random_state = 63)
svc_grid.fit(X_train, y_train)
```

* **Vector Control Regression**
  * Rationale: 
  * Chosen Hyper-Parameters:
    ```{python}
    print("Best SVC parameters:", svc_grid.best_params_)
    ```
  * Results: 
   ```{python}
   print("Best SVC score:", svc_grid.best_score_)
   ```

## Random Forest
```{python}
#| label: rf-model
#| message: false
# Model Creation
# All param grids generated by copilot when asked for a param grid for {model_type}


rf_params = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}
rf_model = RandomForestClassifier(random_state = 63)
rf_grid = RandomizedSearchCV(rf_model, rf_params, cv = 5, scoring = 'recall_macro', n_iter = 100, random_state = 63)
rf_grid.fit(X_train, y_train)
```
* **Random Forest Classifier**
  * Rationale: 
  * Chosen Hyper-Parameters:
    ```{python}
    print("Best RF parameters:", rf_grid.best_params_)
    ```
  * Results: 
   ```{python}
   print("Best RF score:", rf_grid.best_score_)
   ```

## Best Model

```{python}
#| label: assign-best
#| message: false
# Model Creation
# All param grids generated by copilot when asked for a param grid for {model_type}

best_logreg_model = logreg_grid.best_estimator_
best_bayes_model = bayes_grid.best_estimator_
best_svc_model = svc_grid.best_estimator_
best_rf_model = rf_grid.best_estimator_
```

:::

## App Display:

```{python}
#| label: app
#| message: false
# Configure and run App

# Get min/max for each feature for slider ranges had to ask co-pilot to help with getting the range
feature_ranges = {feat: ((ScaledTornados[feat].min()), (ScaledTornados[feat].max())) for feat in feature_names}
ScaledTornados.head()

def create_model_tab(model, feature_names, feature_ranges, model_name):
    sliders = {}

    for feat in feature_names:
        min_val, max_val = feature_ranges[feat]
        sliders[feat] = widgets.FloatSlider(
            value=(min_val + max_val) / 2,
            min=min_val,
            max=max_val,
            step=0.01,
            description=feat,
            continuous_update=False,
            layout=widgets.Layout(width='90%')
        )

    predict_button = widgets.Button(description="Predict", button_style='primary')
    result_label = widgets.HTML(value="")

    def on_predict_clicked(b):
        input_vals = np.array([sliders[feat].value for feat in feature_names]).reshape(1, -1)
        pred = model.predict(input_vals)[0]
        if hasattr(model, "predict_proba"):
            prob = model.predict_proba(input_vals)[0][1]
        else:
            prob = None
        if pred == 1:
            if prob is None:
                result_label.value = "<b style='color:red'>Warning: Conditions are pertinent for a tornado!</b>"
            else:
                result_label.value = f"<b style='color:red'>Warning: Conditions are pertinent for a tornado!<br>Probability: {prob:.2f}</b>"
        else:
            if prob is None:
                result_label.value = "<b>No tornado predicted.</b>"
            else:
                result_label.value = f"<b>No tornado predicted.<br>Probability: {prob:.2f}</b>"
                
    predict_button.on_click(on_predict_clicked)

    slider_box = widgets.VBox([sliders[feat] for feat in feature_names])
    tab_layout = widgets.VBox([
        widgets.HTML(f"<h3>{model_name}: Adjust Weather Conditions</h3>"),
        slider_box,
        predict_button,
        result_label,
    ])
    return tab_layout

# Create tabs for each model
tabs = [
    ("Logistic Regression", best_logreg_model),
    ("Naive Bayes", best_bayes_model),
    ("Support Vector Machine", best_svc_model),
    ("Random Forest", best_rf_model)
]
children = []
for name, model in tabs:
    children.append(create_model_tab(model, feature_names, feature_ranges, name))
tab = widgets.Tab()
tab.children = children
tab.titles = [tabs[i][0] for i in range(len(tabs))]

display(tab)
```



## Questions:

# Any Questions?

Feel free to email me at "tylerhart1@arizona.edu" or reach out on Slack 